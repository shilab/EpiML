row.names = 1
)
sprintf('y size: (%d, %d)', nrow(y), ncol(y))
y <- log(as.matrix(y))
#preprocessing
# cat('Filter the miRNA data with more than 20% missing data', '\n')
# x_filtered <- NULL
# x_filtered_colnames <- NULL
# criteria <- trunc(nrow(x) * (1 - max_percentages_miss_val))
# for (i in 1:ncol(x)) {
#   if (sum(as.numeric(x[, i]) != 0) > criteria) {
#     x_filtered <- cbind(x_filtered, x[, i])
#     x_filtered_colnames<-c(x_filtered_colnames, colnames(x)[i])
#   }
# }
# colnames(x_filtered)<-x_filtered_colnames
# # colnames of x_filtered is same with x
x_filtered <- t(na.omit(t(x)))
cat('Quantile normalization', '\n')
x_filtered_normed <- x_filtered
for (sl in 1:ncol(x_filtered_normed)) {
mat = matrix(as.numeric(x_filtered_normed[, sl]), 1)
mat = t(apply(mat, 1, rank, ties.method = "average"))
mat = qnorm(mat / (nrow(x_filtered_normed) + 1))
x_filtered_normed[, sl] = mat
}
x_preprocessed <- x_filtered_normed
rm(x_filtered, x_filtered_normed, sl, mat)
cat('Main effect estimated using EBEN', '\n')
CV = EBelasticNet.GaussianCV(x_preprocessed, y, nFolds = nFolds, Epis = "no")
Blup1 = EBelasticNet.Gaussian(
x_preprocessed,
y,
lambda = CV$Lambda_optimal,
alpha = CV$Alpha_optimal,
Epis = "no",
verbose = 0
)
Blup_main_sig = Blup1$weight[which(Blup1$weight[, 6] <= 0.05), ]
cat('Substract the main effect', '\n')
index_main <- Blup_main_sig[, 1]
effect_main <- Blup_main_sig[, 3]
y_new <- as.matrix(y) - x_preprocessed[, index_main] %*% (as.matrix(effect_main))
cat('Epistatic effect estimated using EBEN', '\n')
CV_epis = EBelasticNet.GaussianCV(x_preprocessed, y_new, nFolds = nFolds, Epis = "yes")
Blup_epis = EBelasticNet.Gaussian(
x_preprocessed,
y_new,
lambda =  CV_epis$Lambda_optimal,
alpha = CV_epis$Alpha_optimal,
Epis = "yes",
verbose = 0
)
Blup_epis_sig = Blup_epis$weight[which(Blup_epis$weight[, 6] <= 0.05), ]
cat('Final run', '\n')
main_epi_sig_id = rbind(Blup_main_sig[, 1:2], Blup_epis_sig[, 1:2])
x_sig <- NULL
for (i in 1:nrow(main_epi_sig_id)) {
if (main_epi_sig_id[i, 1] == main_epi_sig_id[i, 2]) {
x_sig <- cbind(x_sig, x_preprocessed[, main_epi_sig_id[i, 1]])
}
if (main_epi_sig_id[i, 1] != main_epi_sig_id[i, 2]) {
col <- x_preprocessed[, main_epi_sig_id[i, 1]] * x_preprocessed[, main_epi_sig_id[i, 2]]
x_sig <- cbind(x_sig, col)
}
}
cat('Quantile normalization', '\n')
x_sig_qnormed <- x_sig
for (sl in 1:ncol(x_sig_qnormed)) {
mat = matrix(as.numeric(x_sig_qnormed[, sl]), 1)
mat = t(apply(mat, 1, rank, ties.method = "average"))
mat = qnorm(mat / (nrow(x_sig_qnormed) + 1))
x_sig_qnormed[, sl] = mat
}
rm(x_sig, sl, mat)
CV_full = EBelasticNet.GaussianCV(x_sig_qnormed, y, nFolds = nFolds, Epis = "no")
Blup_full = EBelasticNet.Gaussian(
x_sig_qnormed,
y,
lambda =  CV_full$Lambda_optimal,
alpha = CV_full$Alpha_optimal,
Epis = "no",
verbose = 0
)
Blup_full_sig =  Blup_full$weight[which(Blup_full$weight[, 6] <= 0.05),]
Blup_full_sig[,1:2] <- main_epi_sig_id[Blup_full_sig[,1],1:2]
main_result <- NULL
epsi_result <- NULL
for (i in 1:nrow(Blup_full_sig)) {
if (Blup_full_sig[i, 1] == Blup_full_sig[i, 2]) {
main_result <- rbind(main_result, c(colnames(x_preprocessed)[Blup_full_sig[i, 1]],Blup_full_sig[i,3:6]))
}
if (Blup_full_sig[i, 1] != Blup_full_sig[i, 2]) {
epsi_result <- rbind(epsi_result, c(colnames(x_preprocessed)[Blup_full_sig[i, 1]],colnames(x_preprocessed)[Blup_full_sig[i, 2]],Blup_full_sig[i,3:6]))
}
}
# load library
library('BhGLM');
library('Matrix');
library('foreach');
library('glmnet');
source('cv.bh.R');
library('r2d3')
workspace <- '~/Desktop/samples/'
x_filename <- 'Geno.txt'
y_filename <- 'Pheno.txt'
s0 <- 0.03;
s1 <- 0.5;
nFolds <- 5
seed <- 28213
set.seed(seed)
cat('ssLasso parameters:', '\n')
cat('\tworkspace:', workspace, '\n')
cat('\tx_filename:', x_filename, '\n')
cat('\ty_filename:', y_filename, '\n')
cat('\tnFolds:', nFolds, '\n')
cat('\tseed:', seed, '\n')
cat('read data','\n')
x <- read.table(
file = file.path(workspace, x_filename),
header = TRUE,
check.names = FALSE,
row.names = 1
)
sprintf('features size: (%d, %d)', nrow(x), ncol(x))
y <- read.table(
file = file.path(workspace, y_filename),
header = TRUE,
check.names = FALSE,
row.names = 1
)
features <- as.matrix(x);
colnames(features) <- seq(1,ncol(features));
colnames(features)
geno_stand <- scale(features);
geno_stand <- scale(features);
new_y <- scale(pheno);
new_y_in <- new_y[,1,drop=F];
features <- as.matrix(x);
colnames(features) <- seq(1,ncol(features));
pheno <- as.matrix(y);
geno_stand <- scale(features);
new_y <- scale(pheno);
new_y_in <- new_y[,1,drop=F];
new_y
View(new_y)
View(new_y_in)
###### Main effect-single locus:
sig_index <- which(abs(t(new_y_in) %*% geno_stand/(nrow(geno_stand)-1)) > 0.20);
sig_main <- sig_index;
sig_main
library('EBEN')
workspace <- '~/Desktop/samples/'
x_filename <- 'bc_x.txt'
y_filename <- 'bc_y.txt'
category <- 'microRNA'
nFolds <- 5
max_percentages_miss_val <- 0.2
seed <- 28213
cat('EBEN_train parameters:', '\n')
cat('\tWorkspace:', workspace, '\n')
cat('\tx_filename:', x_filename, '\n')
cat('\ty_filename:', y_filename, '\n')
cat('\tCategory:', category, '\n')
cat('\tnFolds:', nFolds, '\n')
cat('\tMax percentage of missing value:', max_percentages_miss_val, '\n')
cat('\tSeed:', seed, '\n')
set.seed(seed)
# reading data
x <- read.table(
file = file.path(workspace, x_filename),
header = TRUE,
check.names = FALSE,
row.names = 1
)
sprintf('x size: (%d, %d)', nrow(x), ncol(x))
x <- as.matrix(x)
y <- read.table(
file = file.path(workspace, y_filename),
header = TRUE,
row.names = 1
)
sprintf('y size: (%d, %d)', nrow(y), ncol(y))
y <- as.matrix(y)
# preprocessing for different job categories
x_preprocessed <- NULL
y_preprocessed <- NULL
cat('Filter data with more than 20% missing data', '\n')
x_filtered <- x[,colMeans(is.na(x)) < max_percentages_miss_val]
# x_filtered_colnames <- NULL
# criteria <- trunc(nrow(x) * (1 - max_percentages_miss_val))
# for (i in 1:ncol(x)) {
#   if (sum(as.numeric(x[, i]) != 0) > criteria) {
#     x_filtered <- cbind(x_filtered, x[, i])
#     x_filtered_colnames <- c(x_filtered_colnames, colnames(x)[i])
#   }
# }
# colnames(x_filtered) <- x_filtered_colnames
library('preprocessCore')
normalize.quantiles(x)
normalize.quantiles(x_filtered)
x_<-normalize.quantiles(x_filtered)
View(x_)
x[,'hsa-mir-1181']
x_<-x[,'hsa-mir-1181']
x_filtered_normed<-normalize.quantiles(x_filtered)
y_preprocessed <- y
x_filtered_normed[,'hsa-mir-1181']
x_filtered[,'hsa-mir-1181']
x_filtered_normed<-normalize.quantiles(x_filtered)
x_filtered_normed[,'hsa-mir-1181']
View(x_filtered_normed)
colnames(x_filtered)
x_filtered_normed[,15]
cat('Filter data with more than 20% missing data', '\n')
x_filtered <- x[,colMeans(is.na(x)) < max_percentages_miss_val]
# x_filtered_colnames <- NULL
# criteria <- trunc(nrow(x) * (1 - max_percentages_miss_val))
# for (i in 1:ncol(x)) {
#   if (sum(as.numeric(x[, i]) != 0) > criteria) {
#     x_filtered <- cbind(x_filtered, x[, i])
#     x_filtered_colnames <- c(x_filtered_colnames, colnames(x)[i])
#   }
# }
# colnames(x_filtered) <- x_filtered_colnames
cat('Quantile normalization', '\n')
x_filtered_normed<-normalize.quantiles(x_filtered)
x_preprocessed <- x_filtered_normed
cat('Main effect estimated using EBEN', '\n')
CV = EBelasticNet.GaussianCV(x_preprocessed, y_preprocessed, nFolds = nFolds, Epis = "no")
colMeans(is.na(x_preprocessed))
EBelasticNet.GaussianCV?
help(EBelasticNet.GaussianCV)
install.packages('MICE')
install.packages('mice')
data<-iris
summary(iris)
library(missForest)
iris.mis <- prodNA(iris, noNA = 0.1)
summary(iris.mis)
iris.mis<- subset(iris.mis,select=-c(Species))
summary(iris.mis)
# summary miss data in iris usring tabular form
library('mice')
md.pattern(iris.mis)
# visualize missing data in iris
library(VIM)
mice_plot <- aggr(iris.mis, col=c('navyblue','yellow'),
numbers=TRUE, sortVars=TRUE,
labels=names(iris.mis), cex.axis=.7,
gap=3, ylab=c("Missing data","Pattern"))
data<-iris
summary(iris)
library(missForest)
iris.mis <- prodNA(iris, noNA = 0.1)
summary(iris.mis)
iris.mis<- subset(iris.mis,select=-c(Species))
summary(iris.mis)
# summary miss data in iris usring tabular form
library('mice')
md.pattern(iris.mis)
# visualize missing data in iris
library(VIM)
mice_plot <- aggr(iris.mis, col=c('navyblue','yellow'),
numbers=TRUE, sortVars=TRUE,
labels=names(iris.mis), cex.axis=.7,
gap=3, ylab=c("Missing data","Pattern"))
# impute missing value
imputed_data<-mice(iris.mis,m=5, maxit = 50, method = 'pmm', seed = 5000)
summary(imputed_data)
# check imputed values
imputed_data$imp$Sepal.Width
View(imputed_data)
nrow(iris)
# get complete data (2nd out of 5)
complete_data<-complete(imputed_data,2)
View(complete_data)
#build predictive model
fit <- with(data = iris.mis, exp = lm(Sepal.Width ~ Sepal.Length + Petal.Width))
install.packages('Amelia')
library('Amelia')
data('iris')
library(missForest)
iris.mis<-prodNA(iris,noNA = 0.1)
summary(iris.mis)
amelia_fit<-amelia(iris.mis,m=5,parallel = 'multicore', noms = 'Species')
library('EBEN')
workspace <- '~/Desktop/samples/'
x_filename <- 'Geno.txt'
y_filename <- 'Pheno.txt'
category <- 'Gene'
nFolds <- 5
max_percentages_miss_val <- 0.2
seed <- 28213
cat('EBEN_train parameters:', '\n')
cat('\tWorkspace:', workspace, '\n')
cat('\tx_filename:', x_filename, '\n')
cat('\ty_filename:', y_filename, '\n')
cat('\tCategory:', category, '\n')
cat('\tnFolds:', nFolds, '\n')
cat('\tMax percentage of missing value:', max_percentages_miss_val, '\n')
cat('\tSeed:', seed, '\n')
# reading data
x <- read.table(
file = file.path(workspace, x_filename),
header = TRUE,
check.names = FALSE,
row.names = 1
)
sprintf('x size: (%d, %d)', nrow(x), ncol(x))
x <- as.matrix(x)
y <- read.table(
file = file.path(workspace, y_filename),
header = TRUE,
row.names = 1
)
sprintf('y size: (%d, %d)', nrow(y), ncol(y))
y <- as.matrix(y)
# preprocessing for different job categories
x_preprocessed <- NULL
y_preprocessed <- NULL
if (category == 'Gene') {
cat('Filter data with missing data', '\n')
x_filtered <- t(na.omit(t(x)))
# no normlization
x_preprocessed <- scale(x_filtered)
y_preprocessed <- scale(y)
} else if (category == 'microRNA') {
cat('Filter data with more than 20% missing data', '\n')
x_filtered <- x[,colMeans(is.na(x)) < max_percentages_miss_val]
# x_filtered_colnames <- NULL
# criteria <- trunc(nrow(x) * (1 - max_percentages_miss_val))
# for (i in 1:ncol(x)) {
#   if (sum(as.numeric(x[, i]) != 0) > criteria) {
#     x_filtered <- cbind(x_filtered, x[, i])
#     x_filtered_colnames <- c(x_filtered_colnames, colnames(x)[i])
#   }
# }
# colnames(x_filtered) <- x_filtered_colnames
cat('Quantile normalization', '\n')
x_filtered_normed <- x_filtered
for (sl in 1:ncol(x_filtered_normed)) {
mat = matrix(as.numeric(x_filtered_normed[, sl]), 1)
mat = t(apply(mat, 1, rank, ties.method = "average"))
mat = qnorm(mat / (nrow(x_filtered_normed) + 1))
x_filtered_normed[, sl] = mat
}
x_preprocessed <- x_filtered_normed
rm(x_filtered, x_filtered_normed, sl, mat)
y_preprocessed <- y
} else{
# no filtering and no normlization
x_preprocessed <- x
y_preprocessed <- y
}
cat('Main effect estimated using EBEN', '\n')
CV = EBelasticNet.GaussianCV(x_preprocessed, y_preprocessed, nFolds = nFolds, Epis = "no")
Blup1 = EBelasticNet.Gaussian(
x_preprocessed,
y_preprocessed,
lambda = CV$Lambda_optimal,
alpha = CV$Alpha_optimal,
Epis = "no",
verbose = 0
)
Blup_main_sig = matrix(Blup1$weight[which(Blup1$weight[, 6] <= 0.05),], ncol = 6)
View(Blup_main_sig)
help(sslasso)
# load library
library('BhGLM');
library('Matrix');
library('foreach');
library('glmnet');
source('cv.bh.R');
library('r2d3')
workspace <- '~/Desktop/samples/'
x_filename <- 'Geno.txt'
y_filename <- 'Pheno.txt'
s0 <- 0.03;
s1 <- 0.5;
nFolds <- 5
seed <- 28213
cat('ssLasso parameters:', '\n')
cat('\tworkspace:', workspace, '\n')
cat('\tx_filename:', x_filename, '\n')
cat('\ty_filename:', y_filename, '\n')
cat('\tnFolds:', nFolds, '\n')
cat('\tseed:', seed, '\n')
cat('read data','\n')
x <- read.table(
file = file.path(workspace, x_filename),
header = TRUE,
check.names = FALSE,
row.names = 1
)
sprintf('features size: (%d, %d)', nrow(x), ncol(x))
y <- read.table(
file = file.path(workspace, y_filename),
header = TRUE,
check.names = FALSE,
row.names = 1
)
sprintf('y size: (%d, %d)', nrow(y), ncol(y))
features <- as.matrix(x);
colnames(features) <- seq(1,ncol(features));
pheno <- as.matrix(y);
geno_stand <- features;
# ssLASSO requires to scale y
new_y <- scale(pheno);
new_y_in <- new_y[,1,drop=F];
###### Main effect-single locus:
sig_index <- which(abs(t(new_y_in) %*% geno_stand/(nrow(geno_stand)-1)) > 0.20);
sig_main <- sig_index;
######Epistasis effect-single locus:
sig_epi_sum <- NULL;
for(k in 1:(ncol(features)-1)){
single_new <- features[,k,drop=FALSE];
new <- features[,(k+1):ncol(features)];
new_combine <- cbind(new,single_new);
pseudo_allmat <- transform(new_combine,subpseudo=new_combine[,1:(ncol(features)-k)] * new_combine[,ncol(new_combine)]);
colnames(pseudo_allmat) <- paste(colnames(pseudo_allmat), colnames(single_new),sep = "*");
pseudo_mat <- pseudo_allmat[,grep("subpseudo",colnames(pseudo_allmat)),drop=FALSE];
pseudo_mat <- as.matrix(pseudo_mat);
pseudo_mat_stand <- scale(pseudo_mat);
epi_index <- which(abs(t(new_y_in) %*% pseudo_mat_stand/(nrow(pseudo_mat_stand)-1)) > 0.20);
pseudo_mat_stand_epi <- pseudo_mat[,epi_index,drop=FALSE];
sig_epi_sum <- c(sig_epi_sum,colnames(pseudo_mat_stand_epi));
}
res <- matrix(c(sig_main,sig_epi_sum),ncol=1);
res <- gsub("subpseudo.","",res)
new_matrix <- NULL;
for(i in 1:nrow(res)){
if(length(grep("\\*",res[i,1])) == 0){
tmp1 = features[,(as.numeric(res[i,1])),drop=F];
colnames(tmp1) <- res[i,1];
new_matrix <-cbind(new_matrix,tmp1);
}
if(length(grep("\\*",res[i,1])) == 1){
indexes <- strsplit(res[i,1],"\\*");
tmp1 <- features[,as.numeric(indexes[[1]][1]),drop=F] * features[,as.numeric(indexes[[1]][2]),drop=F];
colnames(tmp1) <- res[i,1];
new_matrix <- cbind(new_matrix,tmp1);
}
}
new_matrix <- as.matrix(new_matrix);
f2 <- bmlasso(new_matrix, new_y_in, family = "gaussian", prior = "mde", ss = c(s0,s1),verbose = TRUE);
cv <- cv.bh(f2,ncv=1,nfolds = 3,verbose = TRUE);
tmp_mse <- cv$measures["mse"];
tmp_dev <- cv$measures["deviance"];
Blup <- matrix(f2$beta,ncol=1);
rownames(Blup) <- res;
Blup_estimate <- Blup[which(Blup != 0),1,drop=F];
main_index <- setdiff(1:nrow(Blup_estimate),grep("\\*",rownames(Blup_estimate)));
epi_index <- grep("\\*",rownames(Blup_estimate))
output_main <- matrix("NA",length(main_index),5);
output_epi <- matrix("NA",length(epi_index),6);
output_main[,1] <- matrix(rownames(Blup_estimate),ncol=1)[main_index,,drop=F];
output_main[,2] <- Blup_estimate[main_index,1,drop=F]
epi_ID <- matrix(rownames(Blup_estimate),ncol=1)[epi_index,,drop=F];
output_epi[,1:2] <- matrix(unlist(strsplit(epi_ID,"\\*")),ncol=2);
output_epi[,3] <- Blup_estimate[epi_index,1,drop=F];
colnames(output_main) <- c("feature", "coefficent value", "posterior variance",	"t-value","p-value");
colnames(output_epi) <- c("feature1","feature2", "coefficent value", "posterior variance", "t-value","p-value");
output_main[, 1] <- colnames(x)[as.integer(output_main[, 1])]
output_epi[, 1] <- colnames(x)[as.integer(output_epi[, 1])]
output_epi[, 2] <- colnames(x)[as.integer(output_epi[, 2])]
write.table(
output_main,
file = file.path(workspace, 'main_result.txt'),
quote = F,
sep = "\t",
col.names = T,
row.names = F
)
write.table(
output_epi,
file = file.path(workspace, 'epis_result.txt'),
quote = F,
sep = "\t",
col.names = T,
row.names = F
)
View(output_main)
output_main <- matrix("NA",length(main_index),2);
output_epi <- matrix("NA",length(epi_index),3);
output_main[,1] <- matrix(rownames(Blup_estimate),ncol=1)[main_index,,drop=F];
output_main[,2] <- Blup_estimate[main_index,1,drop=F]
epi_ID <- matrix(rownames(Blup_estimate),ncol=1)[epi_index,,drop=F];
output_epi[,1:2] <- matrix(unlist(strsplit(epi_ID,"\\*")),ncol=2);
output_epi[,3] <- Blup_estimate[epi_index,1,drop=F];
colnames(output_main) <- c("feature", "coefficent value");
colnames(output_epi) <- c("feature1","feature2", "coefficent value");
output_main[, 1] <- colnames(x)[as.integer(output_main[, 1])]
output_epi[, 1] <- colnames(x)[as.integer(output_epi[, 1])]
output_epi[, 2] <- colnames(x)[as.integer(output_epi[, 2])]
write.table(
output_main,
file = file.path(workspace, 'main_result.txt'),
quote = F,
sep = "\t",
col.names = T,
row.names = F
)
write.table(
output_epi,
file = file.path(workspace, 'epis_result.txt'),
quote = F,
sep = "\t",
col.names = T,
row.names = F
)
View(output_main)
