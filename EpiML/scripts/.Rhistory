Epis = "no",
verbose = 0
)
Blup_main_sig = Blup1$weight[which(Blup1$weight[, 6] <= 0.05), ]
View(Blup_main_sig)
x_preprocessed<-x
cat('Main effect estimated using EBEN', '\n')
CV = EBelasticNet.GaussianCV(x_preprocessed, y, nFolds = nFolds, Epis = "no")
View(x)
install.packages('hutils')
# reading data
x <- read.table(
file = file.path(workspace, x_filename),
header = TRUE,
check.names=FALSE,
row.names = 1
)
sprintf('x size: (%d, %d)', nrow(x), ncol(x))
x <- as.matrix(x)
View(x)
drop_empty_cols(x)
library('hutils')
drop_empty_cols(x)
x_filtered <- t(na.omit(t(x)))
View(x_filtered)
ncol(x_filtered)
nrow(x_filtered)
x_preprocessed<-x_filtered
cat('Main effect estimated using EBEN', '\n')
CV = EBelasticNet.GaussianCV(x_preprocessed, y, nFolds = nFolds, Epis = "no")
Blup1 = EBelasticNet.Gaussian(
x_preprocessed,
y,
lambda = CV$Lambda_optimal,
alpha = CV$Alpha_optimal,
Epis = "no",
verbose = 0
)
Blup_main_sig = Blup1$weight[which(Blup1$weight[, 6] <= 0.05), ]
View(Blup_main_sig)
cat('Quantile normalization', '\n')
x_filtered_normed <- x_filtered
for (sl in 1:ncol(x_filtered_normed)) {
mat = matrix(as.numeric(x_filtered_normed[, sl]), 1)
mat = t(apply(mat, 1, rank, ties.method = "average"))
mat = qnorm(mat / (nrow(x_filtered_normed) + 1))
x_filtered_normed[, sl] = mat
}
x_preprocessed <- x_filtered_normed
rm(x_filtered, x_filtered_normed, sl, mat)
cat('Main effect estimated using EBEN', '\n')
CV = EBelasticNet.GaussianCV(x_preprocessed, y, nFolds = nFolds, Epis = "no")
Blup1 = EBelasticNet.Gaussian(
x_preprocessed,
y,
lambda = CV$Lambda_optimal,
alpha = CV$Alpha_optimal,
Epis = "no",
verbose = 0
)
Blup_main_sig = Blup1$weight[which(Blup1$weight[, 6] <= 0.05), ]
View(Blup_main_sig)
library('EBEN')
workspace <- '~/Desktop/samples/'
x_filename <- 'bc_x.txt'
y_filename <- 'bc_y.txt'
nFolds <- 2
max_percentages_miss_val <- 0.2
seed <- 28213
cat('EBEN_train parameters:', '\n')
cat('\tWorkspace:', workspace, '\n')
cat('\tx_filename:', x_filename, '\n')
cat('\ty_filename:', y_filename, '\n')
cat('\tnFolds:', nFolds, '\n')
cat('\tMax percentage of missing value:', max_percentages_miss_val,'\n')
cat('\tSeed:', seed, '\n')
set.seed(seed)
# reading data
x <- read.table(
file = file.path(workspace, x_filename),
header = TRUE,
check.names=FALSE,
row.names = 1
)
sprintf('x size: (%d, %d)', nrow(x), ncol(x))
x <- as.matrix(x)
y <- read.table(
file = file.path(workspace, y_filename),
header = TRUE,
row.names = 1
)
sprintf('y size: (%d, %d)', nrow(y), ncol(y))
y <- log(as.matrix(y))
#preprocessing
# cat('Filter the miRNA data with more than 20% missing data', '\n')
# x_filtered <- NULL
# x_filtered_colnames <- NULL
# criteria <- trunc(nrow(x) * (1 - max_percentages_miss_val))
# for (i in 1:ncol(x)) {
#   if (sum(as.numeric(x[, i]) != 0) > criteria) {
#     x_filtered <- cbind(x_filtered, x[, i])
#     x_filtered_colnames<-c(x_filtered_colnames, colnames(x)[i])
#   }
# }
# colnames(x_filtered)<-x_filtered_colnames
# # colnames of x_filtered is same with x
x_filtered <- t(na.omit(t(x)))
cat('Quantile normalization', '\n')
x_filtered_normed <- x_filtered
for (sl in 1:ncol(x_filtered_normed)) {
mat = matrix(as.numeric(x_filtered_normed[, sl]), 1)
mat = t(apply(mat, 1, rank, ties.method = "average"))
mat = qnorm(mat / (nrow(x_filtered_normed) + 1))
x_filtered_normed[, sl] = mat
}
x_preprocessed <- x_filtered_normed
rm(x_filtered, x_filtered_normed, sl, mat)
cat('Main effect estimated using EBEN', '\n')
CV = EBelasticNet.GaussianCV(x_preprocessed, y, nFolds = nFolds, Epis = "no")
Blup1 = EBelasticNet.Gaussian(
x_preprocessed,
y,
lambda = CV$Lambda_optimal,
alpha = CV$Alpha_optimal,
Epis = "no",
verbose = 0
)
Blup_main_sig = Blup1$weight[which(Blup1$weight[, 6] <= 0.05), ]
cat('Substract the main effect', '\n')
index_main <- Blup_main_sig[, 1]
effect_main <- Blup_main_sig[, 3]
y_new <- as.matrix(y) - x_preprocessed[, index_main] %*% (as.matrix(effect_main))
cat('Epistatic effect estimated using EBEN', '\n')
CV_epis = EBelasticNet.GaussianCV(x_preprocessed, y_new, nFolds = nFolds, Epis = "yes")
Blup_epis = EBelasticNet.Gaussian(
x_preprocessed,
y_new,
lambda =  CV_epis$Lambda_optimal,
alpha = CV_epis$Alpha_optimal,
Epis = "yes",
verbose = 0
)
Blup_epis_sig = Blup_epis$weight[which(Blup_epis$weight[, 6] <= 0.05), ]
View(Blup_epis_sig)
cat('Final run', '\n')
main_epi_sig_id = rbind(Blup_main_sig[, 1:2], Blup_epis_sig[, 1:2])
x_sig <- NULL
for (i in 1:nrow(main_epi_sig_id)) {
if (main_epi_sig_id[i, 1] == main_epi_sig_id[i, 2]) {
x_sig <- cbind(x_sig, x_preprocessed[, main_epi_sig_id[i, 1]])
}
if (main_epi_sig_id[i, 1] != main_epi_sig_id[i, 2]) {
col <- x_preprocessed[, main_epi_sig_id[i, 1]] * x_preprocessed[, main_epi_sig_id[i, 2]]
x_sig <- cbind(x_sig, col)
}
}
View(Blup_main_sig)
cat('Final run', '\n')
main_epi_sig_id = rbind(Blup_main_sig[, 1:2], Blup_epis_sig[, 1:2])
x_sig <- NULL
for (i in 1:nrow(main_epi_sig_id)) {
if (main_epi_sig_id[i, 1] == main_epi_sig_id[i, 2]) {
x_sig <- cbind(x_sig, x_preprocessed[, main_epi_sig_id[i, 1]])
}
if (main_epi_sig_id[i, 1] != main_epi_sig_id[i, 2]) {
col <- x_preprocessed[, main_epi_sig_id[i, 1]] * x_preprocessed[, main_epi_sig_id[i, 2]]
x_sig <- cbind(x_sig, col)
}
}
cat('Quantile normalization', '\n')
x_sig_qnormed <- x_sig
for (sl in 1:ncol(x_sig_qnormed)) {
mat = matrix(as.numeric(x_sig_qnormed[, sl]), 1)
mat = t(apply(mat, 1, rank, ties.method = "average"))
mat = qnorm(mat / (nrow(x_sig_qnormed) + 1))
x_sig_qnormed[, sl] = mat
}
rm(x_sig, sl, mat)
CV_full = EBelasticNet.GaussianCV(x_sig_qnormed, y, nFolds = nFolds, Epis = "no")
Blup_full = EBelasticNet.Gaussian(
x_sig_qnormed,
y,
lambda =  CV_full$Lambda_optimal,
alpha = CV_full$Alpha_optimal,
Epis = "no",
verbose = 0
)
Blup_full_sig =  Blup_full$weight[which(Blup_full$weight[, 6] <= 0.05),]
Blup_full_sig[,1:2] <- main_epi_sig_id[Blup_full_sig[,1],1:2]
main_result <- NULL
epsi_result <- NULL
for (i in 1:nrow(Blup_full_sig)) {
if (Blup_full_sig[i, 1] == Blup_full_sig[i, 2]) {
main_result <- rbind(main_result, c(colnames(x_preprocessed)[Blup_full_sig[i, 1]],Blup_full_sig[i,3:6]))
}
if (Blup_full_sig[i, 1] != Blup_full_sig[i, 2]) {
epsi_result <- rbind(epsi_result, c(colnames(x_preprocessed)[Blup_full_sig[i, 1]],colnames(x_preprocessed)[Blup_full_sig[i, 2]],Blup_full_sig[i,3:6]))
}
}
library('EBEN')
workspace <- '~/Desktop/samples/'
x_filename <- 'bc_x.txt'
y_filename <- 'bc_y.txt'
nFolds <- 2
max_percentages_miss_val <- 0.2
seed <- 28213
cat('EBEN_train parameters:', '\n')
cat('\tWorkspace:', workspace, '\n')
cat('\tx_filename:', x_filename, '\n')
cat('\ty_filename:', y_filename, '\n')
cat('\tnFolds:', nFolds, '\n')
cat('\tMax percentage of missing value:', max_percentages_miss_val,'\n')
cat('\tSeed:', seed, '\n')
set.seed(seed)
# reading data
x <- read.table(
file = file.path(workspace, x_filename),
header = TRUE,
check.names=FALSE,
row.names = 1
)
sprintf('x size: (%d, %d)', nrow(x), ncol(x))
x <- as.matrix(x)
y <- read.table(
file = file.path(workspace, y_filename),
header = TRUE,
row.names = 1
)
sprintf('y size: (%d, %d)', nrow(y), ncol(y))
y <- log(as.matrix(y))
#preprocessing
# cat('Filter the miRNA data with more than 20% missing data', '\n')
# x_filtered <- NULL
# x_filtered_colnames <- NULL
# criteria <- trunc(nrow(x) * (1 - max_percentages_miss_val))
# for (i in 1:ncol(x)) {
#   if (sum(as.numeric(x[, i]) != 0) > criteria) {
#     x_filtered <- cbind(x_filtered, x[, i])
#     x_filtered_colnames<-c(x_filtered_colnames, colnames(x)[i])
#   }
# }
# colnames(x_filtered)<-x_filtered_colnames
# # colnames of x_filtered is same with x
x_filtered <- t(na.omit(t(x)))
cat('Quantile normalization', '\n')
x_filtered_normed <- x_filtered
for (sl in 1:ncol(x_filtered_normed)) {
mat = matrix(as.numeric(x_filtered_normed[, sl]), 1)
mat = t(apply(mat, 1, rank, ties.method = "average"))
mat = qnorm(mat / (nrow(x_filtered_normed) + 1))
x_filtered_normed[, sl] = mat
}
x_preprocessed <- x_filtered_normed
rm(x_filtered, x_filtered_normed, sl, mat)
cat('Main effect estimated using EBEN', '\n')
CV = EBelasticNet.GaussianCV(x_preprocessed, y, nFolds = nFolds, Epis = "no")
Blup1 = EBelasticNet.Gaussian(
x_preprocessed,
y,
lambda = CV$Lambda_optimal,
alpha = CV$Alpha_optimal,
Epis = "no",
verbose = 0
)
Blup_main_sig = Blup1$weight[which(Blup1$weight[, 6] <= 0.05), ]
cat('Substract the main effect', '\n')
index_main <- Blup_main_sig[, 1]
effect_main <- Blup_main_sig[, 3]
y_new <- as.matrix(y) - x_preprocessed[, index_main] %*% (as.matrix(effect_main))
cat('Epistatic effect estimated using EBEN', '\n')
CV_epis = EBelasticNet.GaussianCV(x_preprocessed, y_new, nFolds = nFolds, Epis = "yes")
Blup_epis = EBelasticNet.Gaussian(
x_preprocessed,
y_new,
lambda =  CV_epis$Lambda_optimal,
alpha = CV_epis$Alpha_optimal,
Epis = "yes",
verbose = 0
)
Blup_epis_sig = Blup_epis$weight[which(Blup_epis$weight[, 6] <= 0.05), ]
cat('Final run', '\n')
main_epi_sig_id = rbind(Blup_main_sig[, 1:2], Blup_epis_sig[, 1:2])
x_sig <- NULL
for (i in 1:nrow(main_epi_sig_id)) {
if (main_epi_sig_id[i, 1] == main_epi_sig_id[i, 2]) {
x_sig <- cbind(x_sig, x_preprocessed[, main_epi_sig_id[i, 1]])
}
if (main_epi_sig_id[i, 1] != main_epi_sig_id[i, 2]) {
col <- x_preprocessed[, main_epi_sig_id[i, 1]] * x_preprocessed[, main_epi_sig_id[i, 2]]
x_sig <- cbind(x_sig, col)
}
}
cat('Quantile normalization', '\n')
x_sig_qnormed <- x_sig
for (sl in 1:ncol(x_sig_qnormed)) {
mat = matrix(as.numeric(x_sig_qnormed[, sl]), 1)
mat = t(apply(mat, 1, rank, ties.method = "average"))
mat = qnorm(mat / (nrow(x_sig_qnormed) + 1))
x_sig_qnormed[, sl] = mat
}
rm(x_sig, sl, mat)
CV_full = EBelasticNet.GaussianCV(x_sig_qnormed, y, nFolds = nFolds, Epis = "no")
Blup_full = EBelasticNet.Gaussian(
x_sig_qnormed,
y,
lambda =  CV_full$Lambda_optimal,
alpha = CV_full$Alpha_optimal,
Epis = "no",
verbose = 0
)
Blup_full_sig =  Blup_full$weight[which(Blup_full$weight[, 6] <= 0.05),]
Blup_full_sig[,1:2] <- main_epi_sig_id[Blup_full_sig[,1],1:2]
main_result <- NULL
epsi_result <- NULL
for (i in 1:nrow(Blup_full_sig)) {
if (Blup_full_sig[i, 1] == Blup_full_sig[i, 2]) {
main_result <- rbind(main_result, c(colnames(x_preprocessed)[Blup_full_sig[i, 1]],Blup_full_sig[i,3:6]))
}
if (Blup_full_sig[i, 1] != Blup_full_sig[i, 2]) {
epsi_result <- rbind(epsi_result, c(colnames(x_preprocessed)[Blup_full_sig[i, 1]],colnames(x_preprocessed)[Blup_full_sig[i, 2]],Blup_full_sig[i,3:6]))
}
}
# load library
library('BhGLM');
library('Matrix');
library('foreach');
library('glmnet');
source('cv.bh.R');
library('r2d3')
workspace <- '~/Desktop/samples/'
x_filename <- 'Geno.txt'
y_filename <- 'Pheno.txt'
s0 <- 0.03;
s1 <- 0.5;
nFolds <- 5
seed <- 28213
set.seed(seed)
cat('ssLasso parameters:', '\n')
cat('\tworkspace:', workspace, '\n')
cat('\tx_filename:', x_filename, '\n')
cat('\ty_filename:', y_filename, '\n')
cat('\tnFolds:', nFolds, '\n')
cat('\tseed:', seed, '\n')
cat('read data','\n')
x <- read.table(
file = file.path(workspace, x_filename),
header = TRUE,
check.names = FALSE,
row.names = 1
)
sprintf('features size: (%d, %d)', nrow(x), ncol(x))
y <- read.table(
file = file.path(workspace, y_filename),
header = TRUE,
check.names = FALSE,
row.names = 1
)
features <- as.matrix(x);
colnames(features) <- seq(1,ncol(features));
colnames(features)
geno_stand <- scale(features);
geno_stand <- scale(features);
new_y <- scale(pheno);
new_y_in <- new_y[,1,drop=F];
features <- as.matrix(x);
colnames(features) <- seq(1,ncol(features));
pheno <- as.matrix(y);
geno_stand <- scale(features);
new_y <- scale(pheno);
new_y_in <- new_y[,1,drop=F];
new_y
View(new_y)
View(new_y_in)
###### Main effect-single locus:
sig_index <- which(abs(t(new_y_in) %*% geno_stand/(nrow(geno_stand)-1)) > 0.20);
sig_main <- sig_index;
sig_main
library('EBEN')
workspace <- '~/Desktop/samples/'
x_filename <- 'bc_x.txt'
y_filename <- 'bc_y.txt'
category <- 'microRNA'
nFolds <- 5
max_percentages_miss_val <- 0.2
seed <- 28213
cat('EBEN_train parameters:', '\n')
cat('\tWorkspace:', workspace, '\n')
cat('\tx_filename:', x_filename, '\n')
cat('\ty_filename:', y_filename, '\n')
cat('\tCategory:', category, '\n')
cat('\tnFolds:', nFolds, '\n')
cat('\tMax percentage of missing value:', max_percentages_miss_val, '\n')
cat('\tSeed:', seed, '\n')
set.seed(seed)
# reading data
x <- read.table(
file = file.path(workspace, x_filename),
header = TRUE,
check.names = FALSE,
row.names = 1
)
sprintf('x size: (%d, %d)', nrow(x), ncol(x))
x <- as.matrix(x)
y <- read.table(
file = file.path(workspace, y_filename),
header = TRUE,
row.names = 1
)
sprintf('y size: (%d, %d)', nrow(y), ncol(y))
y <- as.matrix(y)
# preprocessing for different job categories
x_preprocessed <- NULL
y_preprocessed <- NULL
cat('Filter data with more than 20% missing data', '\n')
x_filtered <- x[,colMeans(is.na(x)) < max_percentages_miss_val]
# x_filtered_colnames <- NULL
# criteria <- trunc(nrow(x) * (1 - max_percentages_miss_val))
# for (i in 1:ncol(x)) {
#   if (sum(as.numeric(x[, i]) != 0) > criteria) {
#     x_filtered <- cbind(x_filtered, x[, i])
#     x_filtered_colnames <- c(x_filtered_colnames, colnames(x)[i])
#   }
# }
# colnames(x_filtered) <- x_filtered_colnames
library('preprocessCore')
normalize.quantiles(x)
normalize.quantiles(x_filtered)
x_<-normalize.quantiles(x_filtered)
View(x_)
x[,'hsa-mir-1181']
x_<-x[,'hsa-mir-1181']
x_filtered_normed<-normalize.quantiles(x_filtered)
y_preprocessed <- y
x_filtered_normed[,'hsa-mir-1181']
x_filtered[,'hsa-mir-1181']
x_filtered_normed<-normalize.quantiles(x_filtered)
x_filtered_normed[,'hsa-mir-1181']
View(x_filtered_normed)
colnames(x_filtered)
x_filtered_normed[,15]
cat('Filter data with more than 20% missing data', '\n')
x_filtered <- x[,colMeans(is.na(x)) < max_percentages_miss_val]
# x_filtered_colnames <- NULL
# criteria <- trunc(nrow(x) * (1 - max_percentages_miss_val))
# for (i in 1:ncol(x)) {
#   if (sum(as.numeric(x[, i]) != 0) > criteria) {
#     x_filtered <- cbind(x_filtered, x[, i])
#     x_filtered_colnames <- c(x_filtered_colnames, colnames(x)[i])
#   }
# }
# colnames(x_filtered) <- x_filtered_colnames
cat('Quantile normalization', '\n')
x_filtered_normed<-normalize.quantiles(x_filtered)
x_preprocessed <- x_filtered_normed
cat('Main effect estimated using EBEN', '\n')
CV = EBelasticNet.GaussianCV(x_preprocessed, y_preprocessed, nFolds = nFolds, Epis = "no")
colMeans(is.na(x_preprocessed))
EBelasticNet.GaussianCV?
help(EBelasticNet.GaussianCV)
install.packages('MICE')
install.packages('mice')
data<-iris
summary(iris)
library(missForest)
iris.mis <- prodNA(iris, noNA = 0.1)
summary(iris.mis)
iris.mis<- subset(iris.mis,select=-c(Species))
summary(iris.mis)
# summary miss data in iris usring tabular form
library('mice')
md.pattern(iris.mis)
# visualize missing data in iris
library(VIM)
mice_plot <- aggr(iris.mis, col=c('navyblue','yellow'),
numbers=TRUE, sortVars=TRUE,
labels=names(iris.mis), cex.axis=.7,
gap=3, ylab=c("Missing data","Pattern"))
data<-iris
summary(iris)
library(missForest)
iris.mis <- prodNA(iris, noNA = 0.1)
summary(iris.mis)
iris.mis<- subset(iris.mis,select=-c(Species))
summary(iris.mis)
# summary miss data in iris usring tabular form
library('mice')
md.pattern(iris.mis)
# visualize missing data in iris
library(VIM)
mice_plot <- aggr(iris.mis, col=c('navyblue','yellow'),
numbers=TRUE, sortVars=TRUE,
labels=names(iris.mis), cex.axis=.7,
gap=3, ylab=c("Missing data","Pattern"))
# impute missing value
imputed_data<-mice(iris.mis,m=5, maxit = 50, method = 'pmm', seed = 5000)
summary(imputed_data)
# check imputed values
imputed_data$imp$Sepal.Width
View(imputed_data)
nrow(iris)
# get complete data (2nd out of 5)
complete_data<-complete(imputed_data,2)
View(complete_data)
#build predictive model
fit <- with(data = iris.mis, exp = lm(Sepal.Width ~ Sepal.Length + Petal.Width))
install.packages('Amelia')
library('Amelia')
data('iris')
library(missForest)
iris.mis<-prodNA(iris,noNA = 0.1)
summary(iris.mis)
amelia_fit<-amelia(iris.mis,m=5,parallel = 'multicore', noms = 'Species')
